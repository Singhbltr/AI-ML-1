{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810c2f17",
   "metadata": {},
   "source": [
    "(B)Natural Language Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15080d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from io import StringIO\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbaa096",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('data_in.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d47016f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "389eb051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Comment\n",
      "0  \"Hello there, how are you? Weather is awesome....\n",
      "1  \"Hello Mr. Raja, how are you? Weather is aweso...\n",
      "2  \"Hello Mr. Raja, how are you. Weather is bad. ...\n",
      "3  \"NLP is great technique. It is nice to learn t...\n",
      "4  \"AI is making difference in this world now.  I...\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de3c3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['                                             Comment\\n0  \"Hello there, how are you?', 'Weather is awesome....\\n1  \"Hello Mr. Raja, how are you?', 'Weather is aweso...\\n2  \"Hello Mr. Raja, how are you.', 'Weather is bad.', '...\\n3  \"NLP is great technique.', 'It is nice to learn t...\\n4  \"AI is making difference in this world now.', 'I...']\n"
     ]
    }
   ],
   "source": [
    "sen=sent_tokenize(x)\n",
    "print(sen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b8c1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "                                               Comment\n",
      "0  \"Hello there, how are you?\n",
      "  Weather is awesome....\n",
      "1  \"Hello Mr. Raja, how are you?\n",
      "  Weather is aweso...\n",
      "2  \"Hello Mr. Raja, how are you.\n",
      "  Weather is bad.\n",
      "  ...\n",
      "3  \"NLP is great technique.\n",
      "  It is nice to learn t...\n",
      "4  \"AI is making difference in this world now.\n",
      "  I...)\n"
     ]
    }
   ],
   "source": [
    "sen_ne=ne_chunk(sen)\n",
    "print(sen_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c97391f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out=pd.DataFrame(sen_ne)\n",
    "data_out.to_csv('data_out.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b25b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.read_csv('data_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1be9ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Comment', 'Hello', 'there', 'how', 'are', 'you', 'Weather', 'is', 'awesome', 'Hello', 'Raja', 'how', 'are', 'you', 'Weather', 'is', 'aweso', 'Hello', 'Raja', 'how', 'are', 'you', 'Weather', 'is', 'bad', 'NLP', 'is', 'great', 'technique', 'It', 'is', 'nice', 'to', 'learn', 't', 'AI', 'is', 'making', 'difference', 'in', 'this', 'world', 'now', 'I']\n"
     ]
    }
   ],
   "source": [
    "words=word_tokenize(x)\n",
    "word = [word for word in words if word.isalpha()]\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbc11e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out=pd.DataFrame(word)\n",
    "data_out.to_csv('data_out.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6848cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0\n",
      "0      Comment\n",
      "1        Hello\n",
      "2        there\n",
      "3          how\n",
      "4          are\n",
      "5          you\n",
      "6      Weather\n",
      "7           is\n",
      "8      awesome\n",
      "9        Hello\n",
      "10        Raja\n",
      "11         how\n",
      "12         are\n",
      "13         you\n",
      "14     Weather\n",
      "15          is\n",
      "16       aweso\n",
      "17       Hello\n",
      "18        Raja\n",
      "19         how\n",
      "20         are\n",
      "21         you\n",
      "22     Weather\n",
      "23          is\n",
      "24         bad\n",
      "25         NLP\n",
      "26          is\n",
      "27       great\n",
      "28   technique\n",
      "29          It\n",
      "30          is\n",
      "31        nice\n",
      "32          to\n",
      "33       learn\n",
      "34           t\n",
      "35          AI\n",
      "36          is\n",
      "37      making\n",
      "38  difference\n",
      "39          in\n",
      "40        this\n",
      "41       world\n",
      "42         now\n",
      "43           I\n"
     ]
    }
   ],
   "source": [
    "d1=pd.read_csv('data_out.csv')\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "342f913b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x1=pd.read_csv('data.txt')\n",
    "with open('data.txt') as f:\n",
    "    x1=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9668cf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello there, how are you? Weather is awesome. Its raining here now.\\n', 'Hello Mr. Raja, how are you? Weather is awesome. Its raining here now.\\n', 'Hello Mr. Raja, how are you. Weather is bad. Its heavily raining here now.\\n', 'NLP is great technique. It is nice to learn this technique.\\n', 'AI is making difference in this world now.  It would be helpful for betterment of human life. We need to make advantage of that.\\n']\n"
     ]
    }
   ],
   "source": [
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1c2bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('there', 'EX'), ('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP'), ('Weather', 'NNP'), ('is', 'VBZ'), ('awesome', 'JJ'), ('Its', 'PRP$'), ('raining', 'VBG'), ('here', 'RB'), ('Raja', 'NNP'), ('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP'), ('Weather', 'NNP'), ('is', 'VBZ'), ('awesome', 'JJ'), ('Its', 'PRP$'), ('raining', 'VBG'), ('here', 'RB'), ('Raja', 'NNP'), ('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP'), ('Weather', 'NNP'), ('is', 'VBZ'), ('bad', 'JJ'), ('Its', 'PRP$'), ('heavily', 'RB'), ('raining', 'VBG'), ('here', 'RB'), ('is', 'VBZ'), ('great', 'JJ'), ('technique', 'NN'), ('It', 'PRP'), ('is', 'VBZ'), ('nice', 'JJ'), ('to', 'TO'), ('learn', 'VB'), ('this', 'DT'), ('is', 'VBZ'), ('making', 'VBG'), ('difference', 'NN'), ('in', 'IN'), ('this', 'DT'), ('world', 'NN'), ('now', 'RB'), ('It', 'PRP'), ('would', 'MD'), ('be', 'VB'), ('helpful', 'JJ'), ('for', 'IN'), ('betterment', 'NN'), ('of', 'IN'), ('human', 'JJ'), ('life', 'NN'), ('We', 'PRP'), ('need', 'VBP'), ('to', 'TO'), ('make', 'VB'), ('advantage', 'NN'), ('of', 'IN')]\n"
     ]
    }
   ],
   "source": [
    "x1=str(x1)\n",
    "wrd=word_tokenize(x1)\n",
    "word_tokens = [word for word in wrd if word.isalpha()]\n",
    "pos_word=pos_tag(word_tokens)\n",
    "print(pos_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ad5a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.txt') as f:\n",
    "    x2=f.readlines()\n",
    "x2=str(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58fcf087",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a836a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = word_tokenize(x2)\n",
    "word_tokens = [word for word in word_tokens if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bed046fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weather', 'awesom', 'it', 'rain', 'raja', 'weather', 'awesom', 'it', 'rain', 'raja', 'weather', 'bad', 'it', 'heavili', 'rain', 'great', 'techniqu', 'it', 'nice', 'learn', 'make', 'differ', 'world', 'it', 'would', 'help', 'better', 'human', 'life', 'we', 'need', 'make', 'advantag']\n"
     ]
    }
   ],
   "source": [
    "filtered_sentence = [] \n",
    "  \n",
    "for w in word_tokens: \n",
    "    if w not in stop_words: \n",
    "        filtered_sentence.append(w) \n",
    "\n",
    "Stem_words = []\n",
    "ps =PorterStemmer()\n",
    "for w in filtered_sentence:\n",
    "    rootWord=ps.stem(w)\n",
    "    Stem_words.append(rootWord)\n",
    "#print(filtered_sentence)\n",
    "print(Stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78133e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Weather', 'awesome', 'Its', 'rain', 'Raja', 'Weather', 'awesome', 'Its', 'rain', 'Raja', 'Weather', 'bad', 'Its', 'heavily', 'rain', 'great', 'technique', 'It', 'nice', 'learn', 'make', 'difference', 'world', 'It', 'would', 'helpful', 'betterment', 'human', 'life', 'We', 'need', 'make', 'advantage']\n"
     ]
    }
   ],
   "source": [
    "lemma_word=[]\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "for w in filtered_sentence:\n",
    "    word1 = wordnet_lemmatizer.lemmatize(w, pos = \"n\")\n",
    "    word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n",
    "    word3 = wordnet_lemmatizer.lemmatize(word2, pos = (\"a\"))\n",
    "    lemma_word.append(word3)\n",
    "print(lemma_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aef4e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These words are present in both list ['rain', 'bad', 'great', 'nice', 'learn', 'make', 'world', 'would', 'human', 'life', 'need']\n"
     ]
    }
   ],
   "source": [
    "#compare the both list, which word is in both list\n",
    "same=[]\n",
    "for i in Stem_words:\n",
    "    if i in lemma_word and i not in same:\n",
    "        same.append(i)\n",
    "print(\"These words are present in both list:\",same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f43663f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rose is beautiful 3\n",
      "place is nasty to stay -3\n",
      "this is the beauty of this technique 2\n",
      "concept is explained beautifully in this book 1\n",
      "he annoyed me -2\n",
      "its the supreme place to stay 5\n",
      "i hate this place -3\n",
      "dont annoy the customer -2\n",
      "he has given nasty comments about his stay -3\n",
      "dessert is awesome 4\n",
      "your gift is wonderful 4\n",
      "Overall:  6\n"
     ]
    }
   ],
   "source": [
    "senti_dict={\"hate\":-3,\"hatred\":-3,\"annoyed\":-2,\"annoy\":-2,\"annoyingly\":-2,\"nasty\":-3,\"nice\":2,\"excellent\":3,\"good\":1,\"wonderful\":4,\"best\":3,\"better\":2,\"awesome\":4,\"beautiful\":3,\"beauty\":2,\"beautifully\":1,\"supreme\":5}\n",
    "#pos_words={\"nice\":2,\"excellent\":3,\"good\":1,\"wonderful\":4,\"best\":3,\"better\":2,\"awesome\":4,\"beautiful\":3,\"beauty\":2,\"beautifully\":1,\"supreme\":5}\n",
    "\n",
    "\n",
    "with open('data_senti_analyze.txt') as f:\n",
    "    x1=f.readlines()\n",
    "\n",
    "#print(x1)\n",
    "\n",
    "\n",
    "overall=0\n",
    "for line in x1:\n",
    "    line=line.replace('.','')\n",
    "    line=line.lower().split()\n",
    "    a=sum(senti_dict.get(word,0) for word in line)\n",
    "    overall+=a\n",
    "    print( ' '.join(map(str, line)),a)\n",
    "print(\"Overall: \",overall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334f560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
